# Imports
import pandas as pd
from collections import Counter

"""
changepoint_tally.py takes a .csv containing a table of changepoints as generated by changepoint_analysis.R,
tallies the changepoints per feature and applies thresholds to determine the "true" changepoints per feature.
This is necessary for determining the Tiers in the DOM analysis.

Inputs - name of the .csv with the list of changepoints per parameter setting.
Outputs:
    - A .csv with the changepoint tallies for visualization later
    - Lists of the "true" changepoints per feature (plus "true" multivariate changepoints)

"""

# NAME OF .CSV WITH CHANGEPOINTS
changepoints_table_name = "/Users/madelinehamilton/Documents/python_stuff/bimmuda_dom/output_data/changepoints.csv"
# DESIRED NAME OF TALLY .CSV
tally_csv_name = "/Users/madelinehamilton/Documents/python_stuff/bimmuda_dom/output_data/changepoint_tallies.csv"

"""
identify_clusters() helps when determining overall changepoints for multiple time series, given the individual changepoints
per time series. It identifies clusters of changepoints (changepoints whose positions are close together).

Inputs - a DataFrame containing a column of feature names, a column with a list of changepoint positions for each feature.
         and a column with a list of changepoint tally for each changepoint in the feature's time series.
Outputs - a DataFrame with preliminary overall changepoint clusters to consider
"""
def identify_clusters(df):
    #Â Do value counts for each changepoint
    cpts = sum(list(df['Changepoints']), [])
    value_counts = dict(Counter(cpts))
    preliminary_clusters = []
    # Iterate through the dictionary
    for key in value_counts:
        """
        Consider the current tally m_1, and its year tally y_1. Also consider any other tally m_2, and its year tally y_2.
        Assume y_2 > y_1. We can consider another tally as clustered with the current tally if: y_2 - y_1 <= m_1 + m_2
        """
        m_1 = value_counts[key]
        y_1 = key
        # Iterate through all other keys
        for key2 in value_counts:
            if key2 == key:
                continue
            else:
                m_2 = value_counts[key2]
                y_2 = key2
                if y_1 > y_2:
                    continue
                else:
                    lhs = y_2 - y_1
                    rhs = m_2 + m_1
                    if lhs <= rhs:
                        # If this is true, we've got a preliminary cluster
                        preliminary_clusters.append({"Start Year": y_1, "End Year": y_2, "Sum Tally": m_2 + m_1})
    print()
    print("Preliminary_clusters:")
    for i in range(len(preliminary_clusters)):
        row = preliminary_clusters[i]
        print(row['Start Year'], "-", row['End Year'], ":", row['Sum Tally'])

    print("From here you can select and combine clusters as appropriate.")
    return preliminary_clusters

"""
apply_tally_thresholds() discards changepoints that do not meet a tally threshold, given lists of changepoints and their
tallies.

Inputs - a DataFrame of changepoint tallies as produced by tally_changepoints() (see below)
Outputs - a DataFrame of changepoint tallies that contains only the "true" changepoints (those that exceed the
          threshold tally)
"""
def apply_tally_thresholds(df, threshold=30):
    # For each feature, loop through the "Positions" and "Tallies" lists simultaneously.
    # Mark which positions are above the threshold
    threshold_df = pd.DataFrame(columns=['Feature','Changepoints'])
    features = ['Tonality', 'MIC', 'Pitch_STD', 'MIS', 'OD', 'nPVI', 'RIC', 'Multivariate']
    for f in features:
        row = df.loc[df['Feature'] == f]
        positions = list(row['Positions'])[0]
        tallies = list(list(row['Tallies'])[0])
        new_positions = [positions[i] for i in range(len(positions)) if tallies[i] >= 30]
        dict_for_df = {'Feature': f, 'Changepoints': new_positions}
        threshold_df = threshold_df.append(dict_for_df, ignore_index=True)
    print("True changepoints:")
    print(threshold_df)
    return threshold_df

"""
tally_changepoints() takes a DataFrame of changepoints and creates a dataset of value counts for each changepoint
per feature.

Inputs - directory to .csv containing a DataFrame of changepoints, as produced by changepoint_analysis.R
Outputs - a DataFrame of changepoints tallies with 'Feature' (feature name), 'Positions' (list of changepoint
positions for the feature) and 'Tallies' (list of tallies for each changepoint) columns. 
"""
def tally_changepoints(file):

    # Import the changepoint data
    column_names = ["feature", "alpha", "k", "min_size", "pos"]
    changept_df = pd.read_csv(changepoints_table_name, names=column_names, header=None)
    changept_df = changept_df.iloc[1:]
    changept_df['k'] = changept_df['k'].fillna("NULL")

    # Tally by group
    tallies = changept_df.groupby(['feature'])['pos'].value_counts()

    tally_df = pd.DataFrame(columns=['Feature','Positions','Tallies'])

    # How to I turn this into a useful DataFrame? I guess I have to go the long way
    features = ['Tonality', 'MIC', 'Pitch_STD', 'MIS', 'OD', 'nPVI', 'RIC', 'Multivariate']
    for f in features:
        counts = tallies[f]
        positions = [int(x) for x in list(counts.index)]
        tals = counts.values
        # Convert from time series position to years
        positions = [1951 + x for x in positions]
        dict_for_df = {'Feature': f, 'Positions': positions, 'Tallies': tals}
        tally_df = tally_df.append(dict_for_df, ignore_index=True)

    # Write out the tallies
    tally_df.to_csv(tally_csv_name, index=False)
    return tally_df

tally_info = tally_changepoints(changepoints_table_name)
true_changepoints = apply_tally_thresholds(tally_info)
clusters = identify_clusters(true_changepoints)
